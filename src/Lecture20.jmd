__Applied Complex Analysis (2021)__

# Lecture 20: Orthogonal polynomials and differential equations

This lecture we do the following:

1. Recurrence relationships for Chebyshev and ultraspherical polynomials
    - Conversion
    - Three-term recurrence and Jacobi operators
2. Application: solving differential equations
    - First order constant coefficients differential equations
    - Second order constant coefficient differential equations with boundary conditions
    - Non-constant coefficients
3. Differential equations satisfied by orthogonal polynomials



That is, we introduce recurrences related to ultraspherical polynomials. This allows us to represent general linear differential equations as almost-banded systems.

## Recurrence relationships for Chebyshev and ultraspherical polynomials


We have discussed general properties, but now we want to discuss some classical orthogonal polynomials,
beginning with Chebyshev (first kind) $T_n(x)$, which is orthogonal w.r.t.
$$1\over \sqrt{1-x^2}$$
and ultraspherical $C_n^{(\lambda)}(x)$, which is orthogonal w.r.t.
$$(1-x^2)^{\lambda - \half}$$
for $\lambda > 0$. Note that Chebyshev (second kind) satisfies $U_n(x) = C_n^{(1)}(x)$.

For Chebyshev, recall we have the normalization constant (here we use a superscript $T_n(x) = k_n^{\rm T} x^n + O(x^{n-1})$)
$$
k_0^{\rm T} = 1, k_n^{\rm T} = 2^{n-1}
$$
For Ultraspherical $C_n^{(\lambda)}$, this is
$$
k_n^{(\lambda)} = {2^n (\lambda)_n \over n!} = {2^n \lambda (\lambda+1) (\lambda+2) \cdots (\lambda+n-1)  \over n!}
$$
where $(\lambda)_n$ is the Pochhammer symbol. Note for $U_n(x) = C_n^{(1)}(x)$ this simplifies to $k_n^{\rm U} = k_n^{(1)} = 2^n$.

We have  already found the recurrence for Chebyshev:
$$
x T_n(x) = {T_{n-1}(x) \over 2} +  {T_{n+1}(x) \over 2}
$$
We will show that we can use this to find the recurrence for _all_ ultraspherical polynomials. But first we need some special recurrences.

**Remark** Jacobi, Laguerre, and Hermite all have similar relationships, which will be discussed further in the problem sheet.

### Derivatives

It turns out that the derivative of $T_n(x)$ is precisely a multiple of  $U_{n-1}(x)$, and similarly the derivative of $C_n^{(\lambda)}$ is a multiple of $C_{n-1}^{(\lambda+1)}$.

**Proposition (Chebyshev derivative)**
$$
T_n'(x) = n U_{n-1}(x)
$$

**Proof**
We first show that $T_n'(x)$ is orthogonal w.r.t. $\sqrt{1-x^2}$ to all  polynomials of degree $m < n-1$, denoted $f_m$, using integration by parts:
$$
\begin{align*}
\ip<T_n',f_m>_{\rm U} &= \int_{-1}^1 T_n'(x) f_m(x) \sqrt{1-x^2} \dx \ccr
= -\int_{-1}^1 T_n(x) (f_m'(x)(1-x^2) - xf_m) {1  \over \sqrt{1-x^2}} \dx  \ccr
= - \ip<T_n, f_m'(1-x^2) - x f_m >_{\rm T}  = 0
\end{align*}
$$
since $f_m'(1-x^2) - x f_m $ is degree $m-1 +2 = m+1 < n$.

The constant works out since
$$
T_n'(x) = {\D \over \dx} (2^{n-1} x^n)  + O(x^{n-2}) = n 2^{n-1} x^{n-1} + O(x^{n-2})
$$
■

The exact same proof shows the following:

**Proposition (Ultraspherical derivative)**
$${\D \over \dx} C_n^{(\lambda)}(x) = 2 \lambda  C_{n-1}^{(\lambda+1)}(x)$$

Like the three-term recurrence and Jacobi operators, it is useful to express this in matrix form. That is, for the derivatives of $T_n(x)$ we get
$$
{\D \over \dx}  \begin{pmatrix} T_0(x) \\ T_1(x) \\ T_2(x) \\ \vdots \end{pmatrix}= \begin{pmatrix}
0 \cr
1 \cr
& 2 \cr
&& 3 \cr
&&&\ddots
\end{pmatrix} \begin{pmatrix} U_0(x) \\ U_1(x) \\ U_2(x) \\ \vdots \end{pmatrix}
$$
which lets us know that, for
$$
f(x) = (T_0(x),T_1(x),\ldots) \begin{pmatrix} f_0\\f_1\\\vdots \end{pmatrix}
$$
we have a derivative operator in coefficient space as
$$
f'(x) = (U_0(x),U_1(x),\ldots)\begin{pmatrix}
0 & 1 \cr
&& 2 \cr
&&& 3 \cr
&&&&\ddots
\end{pmatrix}  \begin{pmatrix} f_0\\f_1\\\vdots \end{pmatrix}
$$

_Demonstration_ Here we see that applying a matrix to a vector of coefficients successfully calculates the derivative:
```julia
using ApproxFun, Plots, LinearAlgebra
f = Fun(x -> cos(x^2), Chebyshev())   # f is expanded in Chebyshev coefficients
n = ncoefficients(f)   # This is the number of coefficients
D = zeros(n-1,n)
for k=1:n-1
    D[k,k+1] = k
end
D
```
Here `D*f.coefficients` gives the vector of coefficients corresponding to the derivative, but now the coefficients are in the $U_n(x)$ basis, that is, `Ultraspherical(1)`:
```julia
fp = Fun(Ultraspherical(1), D*f.coefficients)
fp(0.1)
```
Indeed, it matches the "true" derivative:
```julia
f'(0.1),-2*0.1*sin(0.1^2)
```

Note that in ApproxFun.jl we can construct these operators rather nicely:
```julia
D = Derivative()
(D*f)(0.1)
```
Here we see that we can produce the ∞-dimensional version as follows:
```julia
D : Chebyshev() → Ultraspherical(1)
```
### Conversion



We can convert between any two polynomial bases using a lower triangular operator, because their spans are equivalent.
In the case of Chebyshev and ultraspherical polynomials, they have the added property that they are banded.

**Proposition (Chebyshev T-to-U conversion)**
$$
\begin{align*}
 T_0(x) &= U_0(x) \\
 T_1(x) &= {U_1(x) \over 2} \\
 T_n(x) &= {U_n(x) \over 2} - {U_{n-2}(x) \over 2}
\end{align*}
$$

**Proof**

Before we do the proof, note that the fact that there are limited non-zero entries follows immediately: if $m < n-2$ we have
$$
\ip<T_n, U_m>_{\rm U} = \ip<T_n, (1-x^2)U_m>_{\rm T} = 0
$$

To actually determine the entries, we use the trigonometric formulae. Recall for $x = (z + z^{-1})/2$, $z = \E^{\I \theta}$, we have
$$
\begin{align*}
T_n(x) &= \cos n \theta = {z^{-n} + z^n \over 2}\\
U_n(x) &= {\sin (n+1) \theta \over \sin \theta} = {z^{n+1} - z^{-n-1} \over z - z^{-1}} = z^{-n} + z^{2-n} + \cdots +  \cdots + z^{n-2} + z^n
\end{align*}
$$
The result follows immediately.

■

**Corollary (Ultraspherical λ-to-(λ+1) conversion)**
$$
C_n^{(\lambda)}(x) = {\lambda \over n+ \lambda} (C_n^{(\lambda+1)}(x) - C_{n-2}^{(\lambda+1)}(x))
$$

**Proof** This follows from differentiating the previous result. For example:
$$
\begin{align*}
 {\D\over \dx} T_0(x) &= {\D\over \dx} U_0(x) \\
 {\D\over \dx} T_1(x) &= {\D\over \dx} {U_1(x) \over 2} \\
{\D\over \dx} T_n(x) &= {\D\over \dx} \left({U_n(x) \over 2} - {U_{n-2} \over 2} \right)
\end{align*}
$$
becomes
$$
\begin{align*}
    0 &= 0\\
    U_0(x) &= C_0^{(2)}(x) \\
   n U_{n-1}(x) &= C_{n-1}^{(2)}(x)  - C_{n-3}^{(2)}(x)
\end{align*}
$$
Differentiating this repeatedly completes the proof.

■


Note we can write this in matrix form, for example, we have
$$
\underbrace{\begin{pmatrix}1 \cr
                    0 & \half\cr
                       -\half & 0 & \half \cr
                           &\ddots &\ddots & \ddots\end{pmatrix} }_{(R_T^U)^\top} \begin{pmatrix}
                           U_0(x) \\ U_1(x) \\ U_2(x) \\ \vdots \end{pmatrix}  =  \begin{pmatrix} T_0(x) \\ T_1(x) \\ T_2(x) \\ \vdots \end{pmatrix}
$$

therefore,
$$
f(x) =  (T_0(x),T_1(x),\ldots) \begin{pmatrix} f_0\\f_1\\\vdots \end{pmatrix} =  (U_0(x),U_1(x),\ldots) R_T^U \begin{pmatrix} f_0\\f_1\\\vdots \end{pmatrix}
$$

Again, we can construct this nicely in ApproxFun:
```julia
R_TU = I : Chebyshev() → Ultraspherical(1)

f = Fun(exp, Chebyshev())
g = R_TU*f

g(0.1) , exp(0.1)
```
### Ultraspherical Three-term recurrence

**Theorem (three-term recurrence for Chebyshev U)**
$$
\begin{align*}
x U_0(x) &= {U_1(x) \over 2} \\
x U_n(x) &= {U_{n-1}(x) \over 2} + {U_{n+1}(x) \over 2}
\end{align*}
$$

**Proof**
Differentiating
$$
\begin{align*}
 x T_0(x) &= T_1(x) \\
x T_n(x)  &=  {T_{n-1}(x) \over 2} + {T_{n+1}(x) \over 2}
\end{align*}
$$
we get
$$
\begin{align*}
  T_0(x) &= U_0(x) \\
 T_n(x) + n x U_{n-1}(x)  &=  {(n-1) U_{n-2}(x) \over 2} + {(n+1) U_n(x) \over 2}
\end{align*}
$$
substituting in the conversion $T_n(x) = (U_n(x) - U_{n-2}(x))/2$ we get
$$
\begin{align*}
  T_0(x) &= U_0(x) \\
 n x U_{n-1}(x)  &=  {(n-1) U_{n-2}(x) \over 2} + {(n+1) U_n(x) \over 2} - (U_n(x) - U_{n-2}(x))/2 = {n U_{n-2}(x) \over 2} + {n U_n(x) \over 2}
\end{align*}
$$
■

Differentiating this theorem again and applying the conversion we get the following

**Corollary (three-term recurrence for ultraspherical)**
$$
\begin{align*}
x C_0^{(\lambda)}(x) &= {1 \over 2\lambda } C_1^{(\lambda)}(x) \\
 x C_n^{(\lambda)}(x) &=  {n+2\lambda-1 \over 2(n+\lambda)} C_{n-1}^{(\lambda)}(x) + {n+1 \over 2(n+\lambda)} C_{n+1}^{(\lambda)}(x)
\end{align*}
$$

Here's an example of the Jacobi operator (which is the transpose of the multiplication by $x$ operator):
```julia
Multiplication(Fun(), Ultraspherical(2))'
```

## Application: solving differential equations

The preceding results allowed us to represent

1. Differentiation
2. Conversion
3. Multiplication

as banded operators. We will see that we can combine these, along with

4. Evaluation

to solve ordinary differential equations.

### First order, constant coefficient differential equations

Consider the simplest ODE:
$$
\begin{align*}
u(0) &= 1 \\
u'(x) - u(x) &= 0, \qquad x \in [-1, 1]
\end{align*}
$$
and suppose we represent $u(x)$ in its Chebyshev expansion, with coefficients to be determined. In other words, we want to calculate coefficients $u_k$ such that
$$
u(x) = \sum_{k=0}^\infty u_k T_k(x) = (T_0(x), T_1(x), \ldots) \begin{pmatrix} u_0 \\ u_1 \\ \vdots \end{pmatrix}
$$
In this case we know that $u(x) = \E^x$, but we would still need other means to calculate $u_k$ (They are definitely not as simple as Taylor series coefficients).

We can express the constraints as acting on the coefficients. For example, we have
$$
u(0) = (T_0(0), T_1(0), \ldots) \begin{pmatrix} u_0\\u_1\\\vdots \end{pmatrix} = (1,0,-1,0,1,\ldots)  \begin{pmatrix} u_0\\u_1\\\vdots \end{pmatrix}
$$
We also have
$$
u'(x) = (U_0(x),U_1(x),\ldots) \begin{pmatrix}
0 & 1 \cr
&& 2 \cr
&&& 3 \cr
&&&&\ddots
\end{pmatrix}\begin{pmatrix} u_0\\u_1\\\vdots \end{pmatrix}
$$
To represent $u'(x) - u(x)$, we need to make sure the bases are compatible. In other words, we want to express $u(x)$ in its $U_k(x)$ basis using the conversion operator $R_T^{U}$:
$$
u(x) = (U_0(x),U_1(x),\ldots) \begin{pmatrix}
    1 &0 & -\half \cr
& \half & 0 & -\half \cr
&&\ddots & \ddots & \ddots
\end{pmatrix}\begin{pmatrix} u_0\\u_1\\\vdots \end{pmatrix}
$$

Which gives us,
$$
u'(x) - u(x) =  (U_0(x),U_1(x),\ldots)  \begin{pmatrix}
    -1 &1 & \half \cr
& -\half & 2 & \half \cr
&& -\half & 3 & \half \cr
&&&\ddots & \ddots & \ddots
\end{pmatrix} \begin{pmatrix} u_0\\u_1\\\vdots \end{pmatrix}
$$


Combing the differential part and the evaluation part, we arrive at an (infinite) system of equations for the coefficients $u_0,u_1,\dots$:
$$
\begin{pmatrix}
      1 & 0 & -1 & 0 & 1 & \cdots \\
    -1 &1 & \half \cr
& -\half & 2 & \half \cr
&& -\half & 3 & \half \cr
&&&\ddots & \ddots & \ddots
\end{pmatrix} \begin{pmatrix} u_0\\u_1\\\vdots \end{pmatrix}  = \begin{pmatrix} 1 \\ 0 \\ 0 \\ \vdots \end{pmatrix}
$$

How to solve this system is outside the scope of this course (though a simple approach is to truncate the infinite system to finite systems). We can however do this in ApproxFun:
```julia
B  = Evaluation(0.0) : Chebyshev()
D  = Derivative() : Chebyshev() → Ultraspherical(1)
R_TU = I : Chebyshev() → Ultraspherical(1)
L = [B;
     D - R_TU]
```
We can solve this system as follows:
```julia
u = L \ [1; 0]
plot(u;legend=false)
```
It matches the "true" result:
```julia
u(0.1) , exp(0.1)
```
Note we can incorporate right-hand sides as well, for example, to solve $u'(x) - u(x) = f(x)$, by expanding $f$ in its Chebyshev U series.

### Second-order constant coefficient equations

This approach extends to second-order constant-coefficient equations by using ultraspherical polynomials.  Consider
$$
\begin{align*}
u(-1) &= 1\\
u(1) &= 0\\
u''(x) + u'(x)  + u(x) &= 0
\end{align*}
$$
Evaluation works as in the first-order case. To handle second-derivatives, we need $C^{(2)}$ polynomials:
```julia
D₀ = Derivative() : Chebyshev() → Ultraspherical(1)
D₁ = Derivative() : Ultraspherical(1) → Ultraspherical(2)
D₁*D₀  # 2 zeros not printed in (1,1) and (1,2) entry
```
For the identity operator, we use two conversion operators:
```julia
R_TU = I : Chebyshev() → Ultraspherical(1)
R_U2 = I : Ultraspherical(1) → Ultraspherical(2)
R_T2 = R_U2*R_TU
```
And for the first derivative, we use a derivative and then a conversion:
```julia
R_U2*D₀  # or could have been D₁*R_TU
```
Putting everything together we get:
```julia
B₋₁ = Evaluation(-1) : Chebyshev()
B₁ = Evaluation(1) : Chebyshev()
# u(-1)
# u(1)
# u'' + u' +u

L = [B₋₁;
     B₁;
     D₁*D₀ + R_U2*D₀ + R_U2*R_TU]

u = L \ [1.0,0.0,0.0]
plot(u;legend=false)
```

### Variable coefficients

Consider the Airy ODE
$$
\begin{align*}
u(-1) &= 1\\
u(1) &= 0\\
u''(x) - xu(x) &= 0
\end{align*}
$$
to handle this, we need only use the Jacobi operator to represent multiplication by $x$:
```julia
x = Fun()
X = Multiplication(x) : Chebyshev() → Chebyshev()  # transpose of the Jacobi operator
```
We set up the system as follows:
```julia
L = [B₋₁;   # u(-1)
     B₁ ;   # u(1)
     D₁*D₀ - R_U2*R_TU*X]   # u'' - x*u

u = L \ [1.0;0.0;0.0]
plot(u; legend=false)
```
If we introduce a small parameter, that is, solve
$$
\begin{align*}
u(-1) &= 1\\
u(1) &= 0\\
\epsilon u''(x) - xu(x) &= 0
\end{align*}
$$
we can see it's pretty hard to compute solutions:
```julia
ε = 1E-6
L = [B₋₁;
     B₁ ;
     ε*D₁*D₀ - R_U2*R_TU*X]

u = L \ [1.0;0.0;0.0]
plot(u; legend=false)
```
Because of the banded structure, this can be solved fast:
```julia
ε = 1E-10
L = [B₋₁;
     B₁ ;
     ε*D₁*D₀ - R_U2*R_TU*X]

@time u = L \ [1.0;0.0;0.0]
@show ncoefficients(u);
```
To handle other variable coefficients, first consider a polynomial $p(x)$. If Multiplication by $x$ is represented by multiplying the coefficients by $J^\top$, then multiplication by $p$ is represented by multiplying the coefficients by $p(J^\top)$:
```julia
M = -I + X + (X)^2  # represents -1+x+x^2

ε = 1E-6
L = [B₋₁;
     B₁ ;
     ε*D₁*D₀ - R_U2*R_TU*M]

@time u = L \ [1.0;0.0;0.0]

@show ε*u''(0.1) - (-1+0.1+0.1^2)*u(0.1)
plot(u)
```

For other smooth functions, we first approximate in a polynomial basis,  and without loss of generality we use Chebyshev T basis. For example, consider
$$
\begin{align*}
u(-1) &= 1\\
u(1) &= 0\\
\epsilon u''(x) - \E^x u(x) &= 0
\end{align*}
$$
where
$$
\E^x  \approx p(x) = \sum_{k=0}^{m-1} p_k T_k(x)
$$
Evaluating at a point $x$, recall Clenshaw's algorithm:
$$
\begin{align*}
\gamma_{n-1} &= 2p_{n-1} \\
\gamma_{n-2} &= 2p_{n-2} + 2x \gamma_{n-1} \\
\gamma_{n-3} &= 2 p_{n-3} + 2x \gamma_{n-2} - \gamma_{n-1} \\
& \vdots \\
\gamma_1 &= p_1 + x \gamma_2 - \half \gamma_3 \\
p(x) = \gamma_0 &= p_0 + x \gamma_1 - \half \gamma_2
\end{align*}
$$
If multiplication by $x$ becomes $J^\top$, then multiplication by $p(x)$ becomes $p(J^\top)$, and hence we calculate:
$$
\begin{align*}
\Gamma_{n-1} &= 2p_{n-1}I \\
\Gamma_{n-2} &= 2p_{n-2}I + 2J^\top \Gamma_{n-1} \\
\Gamma_{n-3} &= 2 p_{n-3}I + 2J^\top \Gamma_{n-2} - \Gamma_{n-1} \\
& \vdots \\
\Gamma_1 &= p_1I + J^\top \Gamma_2 - \half \Gamma_3 \\
p(J^\top) = \Gamma_0 &= p_0 + J^\top \Gamma_1 - \half \Gamma_2
\end{align*}
$$

Here is an example:
```julia
p = Fun(exp, Chebyshev()) # polynomial approximation to exp(x)
M = Multiplication(p) : Chebyshev() # constructed using Clenshaw:

ε = 1E-6
L = [B₋₁;
     B₁ ;
     ε*D₁*D₀ + R_U2*R_TU*M]

@time u = L \ [1.0;0.0;0.0]

@show ε*u''(0.1) + exp(0.1)*u(0.1)
plot(u)
```

# Differential equations satisfied by orthogonal polynomials


This lecture we do the following:

1. Differential equations for orthogonal polynomials
    - Sturm–Liouville equations
    - Weighted differentiation for ultraspherical polynomials
    - Differential equation for ultraspherical polynomials
2. Application: Eigenstates of Schrödinger operators with quadratic potentials



The three classical weights are (Hermite) $w(x) = \E^{-x^2}$, (Laguerre) $w_\alpha(x) = x^\alpha \E^{-x}$ and (Jacobi) $w_{\alpha,\beta}(x) = (1-x)^\alpha (1+x)^\beta$.
Note all weights form a simple hierarchy: when differentiated, they give a linear polynomial times the previous weight in the hierarchy.  For Hermite,
$$
{\D \over \dx} w(x) = -2x w(x)
$$
for Laguerre,
$$
{\D \over \dx} w^{(\alpha)}(x) = (\alpha  - x) w^{(\alpha-1)}(x)
$$
and for Jacobi
$$
{\D \over \dx} w^{(\alpha,\beta)}(x) = (\beta(1-x) - \alpha(1+x)) w^{(\alpha-1,\beta-1)}(x)
$$
These relationships  lead to simple differential equations that have the classical orthogonal polynomials as eigenfunctions.

### Sturm–Liouville operator
We first consider a simple class of operators that are self-adjoint:

**Proposition (Sturm–Liouville self-adjointness)** Consider the weighted inner product
$$
\ip<f,g>_w = \int_a^b f(x) g(x) w(x) \dx
$$
then for any continuously differentiable function $q(x)$ satisfying $q(a) = q(b) = 0$, the operator
$$
Lu = {1 \over w(x)} {\D \over \dx}\left[ q(x) {\D u\over \dx} \right]
$$
is self-adjoint in the sense
$$
\ip<L f,g>_w = \ip<f, Lg>_w
$$

**Proof** Simple integration by parts argument:
$$
\begin{align*}
\ip<L f,g>_w &= \int_a^b {\D \over \dx}\left[ q(x) {\D u\over \dx}\right]  g(x)\dx \ccr
=  -\int_a^b q(x) {\D u\over \dx}    {\D g\over \dx} \dx =  \int_a^b   u(x)  {\D \over \dx} \left[ q(x) {\D g\over \dx}\right] \dx \ccr
=
 \int_a^b   u(x)  {1 \over w(x)} {\D \over \dx}\left[q(x) {\D g\over \dx}\right] w(x) \dx = \ip<f, Lg>_w
 \end{align*}
$$

■

We claim that the classical orthogonal polynomials are eigenfunctions of a Sturm–Liouville problem, that is, in each case there exists a $q(x)$ so that
$$
L p_n(x) = \lambda_n p_n(x)
$$
where $\lambda_n$ is the (real) eigenvalue. We will derive this for the ultraspherical polynomials.


### Weighted differentiation for ultraspherical polynomials

We have already seen that Chebyshev and ultraspherical polynomials have simple expressions for derivatives where we decrement the degree and increment the parameter:
$$
\begin{align*}
{\D \over \dx } T_n(x) & = n U_{n-1}(x) = n C_{n-1}^{(1)}(x) \\
{\D \over \dx } C_n^{(\lambda)}(x) &= 2 \lambda C_{n-1}^{(\lambda+1)}(x)
\end{align*}
$$
In this section, we see that differentiating the weighted polynomials actually decrements the parameter and increments the degree:

**Proposition (weighted differentiation)**
$$
\begin{align*}
{\D \over \dx }[\sqrt{1-x^2} U_n(x)] &= - {n+1 \over \sqrt{1-x^2}} T_{n+1}(x) \\
{\D \over \dx }[(1-x^2)^{\lambda-\half} C_n^{(\lambda)}(x)] & = -{(n+1) (n+2 \lambda-1) \over 2 (\lambda-1) }  (1-x^2)^{\lambda - {3 \over 2}} C_{n+1}^{(\lambda-1)}(x)
\end{align*}
$$
**Proof** We show the first result by showing that the left-hand side is orthogonal to all  polynomials of degree less than $n+1$ by integration by parts:
$$
\ip< \sqrt{1-x^2} {\D \over \dx }[\sqrt{1-x^2} U_n(x)], p_m(x)>_{\rm T} = -\int_{-1}^1 \sqrt{1-x^2} U_n(x) p_m' \dx =0
$$
Note that
$$
\sqrt{1-x^2} {\D \over \dx } \sqrt{1-x^2} f(x) = (1-x^2) f'(x) - x f(x)
$$
Thus we just have to verify the constant in front:
$$
\sqrt{1-x^2} {\D \over \dx }[\sqrt{1-x^2} U_n(x) = (-n -1) 2^n x^{n+1}
$$

The other ultraspherical polynomial follow similarly.
■


### Eigenvalue equation for Ultraspherical polynomials

Note that differentiating increments the parameter and decrements the degree while weighted differentiation decrements the parameter and increments the degree. Therefore combining them brings us back to where we started.

In the case of Chebyshev polynomials, this gives us a Sturm–Liouville equation:
$$
\sqrt{1-x^2} {\D \over \dx} \sqrt{1-x^2} {\D T_n \over \dx} =
n \sqrt{1-x^2} {\D \over \dx} \sqrt{1-x^2} U_{n-1}(x) = -n^2 T_n(x)
$$

Note that the chain rule gives us a simple expression as
$$
(1-x^2) {\D^2 T_n \over \dx^2} -x {\D T_n \over \dx} = -n^2 T_n(x)
$$

Similarly,
$$
(1-x^2)^{\half - \lambda} {\D \over \dx}(1-x^2)^{\lambda + \half} {\D C_n^{(\lambda)} \over \dx} = -n (n+2 \lambda) C_n^{(\lambda)}(x)
$$
or in other words,
$$
(1-x^2) {\D^2 C_n^{(\lambda)} \over \dx^2} - (2\lambda+1) x {\D C_n^{(\lambda)} \over \dx}  = -{n (n+2 \lambda) \over 2\lambda}C_n^{(\lambda)}(x)
$$
